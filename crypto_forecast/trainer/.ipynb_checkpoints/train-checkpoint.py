import os
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
import torch.multiprocessing as mp
from torchvision import transforms
from torch.utils.data import DataLoader

import mlflow

from preprocessor.data_preparation import TimeseriesDataset, ToTensor

from utils.logger import setup_logger
from utils.utils import PROGRESS_BAR_FORMAT

# mp.set_start_method('spawn', force=True)
LOGGER = setup_logger(__name__, 'train_workflow.log')


def train(dataset, model, batch_size, num_epochs, learning_rate, device):
    """
    Î™®Îç∏ ÌïôÏäµ

    parameter
    ----------
    dataset (tuple): inputÍ≥º label arrayÎ°ú Ïù¥Î£®Ïñ¥ÏßÑ tuple
    model (torch.nn):
    batch_size (int):
    num_epochs (int):
    learning_rate(float): 
    device (str):
    
    """
    X, y = dataset
    
    dataset = TimeseriesDataset(
        feat=X,
        label=y, 
        transform=transforms.Compose([
            ToTensor()
        ])
    )
    
    dataloader = DataLoader(
        dataset, 
        batch_size=batch_size, 
        shuffle=True,
        num_workers=0
    )
    
    model.to(device)
    model.train()   
    criterion = nn.MSELoss()
    optimizer = optim.Adam(model.parameters(), lr=learning_rate)
    
    print(('%20s'*4)%('Epoch', 'Iteration', 'GPU_Mem', 'Loss'))
    for epoch in range(num_epochs):
        for step, mini_batch in enumerate(dataloader):
#         with tqdm(dataloader, total=len(dataloader), bar_format=PROGRESS_BAR_FORMAT) as tq:
#             for step, mini_batch in enumerate(tq):
                    
            optimizer.zero_grad()
            feat = mini_batch['feature'].to(device)
            label = mini_batch['label'].to(device)
            pred = model(feat)            
            
            loss = criterion(pred, label)
            loss.backward()
            optimizer.step()

            mem = f"{torch.cuda.memory_reserved()/1E9 if torch.cuda.is_available() else 0:.3g}G"
#             tq.set_description(('%20s'*4)%(f"{epoch+1}/{num_epochs}", f"{step}/{len(dataloader)}", mem, f"{loss.item():.4}"))
            if step % 500 == 0:
                print(('%20s'*4)%(f"{epoch+1}/{num_epochs}", f"{step}/{len(dataloader)}", mem, f"{loss.item():.4}"))


def setup_experiment(experiment_name, artifact_location):
    
    try:
        mlflow.create_experiment(
            experiment_name, 
            artifact_location=artifact_location
        )

        LOGGER.info(
            f"üß™ Experiment {experiment_name} is not Exist. \
            Create Experiment."
        )
    except:
        LOGGER.info(
            f"üß™ Experienmt {experiment_name} is Already Exist. \
            Execute Run on the \"{experiment_name}\"."
        )
            
    # set experiment
    mlflow.set_experiment(experiment_name)